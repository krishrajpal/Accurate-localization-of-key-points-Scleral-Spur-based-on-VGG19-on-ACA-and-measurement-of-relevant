{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFC4_w6DQkjV",
        "outputId": "970fa8e1-dccf-48d7-9eb9-6edc393a5da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Project': No such file or directory\n",
            "Cloning into 'Project'...\n",
            "remote: Enumerating objects: 323, done.\u001b[K\n",
            "remote: Counting objects: 100% (276/276), done.\u001b[K\n",
            "remote: Compressing objects: 100% (247/247), done.\u001b[K\n",
            "remote: Total 323 (delta 45), reused 252 (delta 25), pack-reused 47\u001b[K\n",
            "Receiving objects: 100% (323/323), 4.84 MiB | 3.89 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -r Project\n",
        "!git clone https://github.com/krishrajpal/Accurate-localization-of-key-points-Scleral-Spur-based-on-VGG19-on-ACA-and-measurement-of-relevant.git Project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LePSCLbhOgks",
        "outputId": "1a4ea724-1710-4c5c-f690-b6f653bf5be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 86s 31s/step - loss: 11745.4766 - val_loss: 688.1715\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 85s 30s/step - loss: 1762.3556 - val_loss: 2887.8879\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 84s 30s/step - loss: 2127.8384 - val_loss: 4752.0474\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 85s 30s/step - loss: 2443.6162 - val_loss: 1600.0013\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 96s 36s/step - loss: 664.7277 - val_loss: 78.0888\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 85s 30s/step - loss: 174.3988 - val_loss: 686.4517\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 84s 30s/step - loss: 624.8579 - val_loss: 1162.5129\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 85s 30s/step - loss: 655.3856 - val_loss: 776.5710\n",
            "Epoch 9/10\n",
            "2/3 [===================>..........] - ETA: 23s - loss: 355.9516"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load your data\n",
        "x_train = np.load('/content/Project/npy/x_train.npy')  # Assuming you have numpy arrays saved as 'train_data.npy'\n",
        "y_train = np.load('/content/Project/npy/y_train.npy')  # Assuming you have numpy arrays saved as 'train_labels.npy'\n",
        "x_test = np.load('/content/Project/npy/x_test.npy')  # Assuming you have numpy arrays saved as 'test_data.npy'\n",
        "y_test = np.load('/content/Project/npy/y_test.npy')  # Assuming you have numpy arrays saved as 'test_labels.npy'\n",
        "\n",
        "# Preprocess your data (normalize, etc.)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define your model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(248, 248, 3))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG19\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(2)(x)  #Predict 2 coordinates\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BAFguPUWF2k",
        "outputId": "1e77124f-89ad-4bbd-b075-625b2f7fd330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 14s 14s/step\n",
            "Mean Squared Error: 76.23718108777136\n",
            "Mean Absolute Error: 6.820522644940544\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# Predict on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xTkoezWNBF9S"
      },
      "outputs": [],
      "source": [
        "model.save('vgg19_coordinates_model_1.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "jhP1QataIjN_",
        "outputId": "8b69ad84-37ad-412c-b81f-6ef413e51d10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-867b5f512fbf>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m model.fit(datagen.flow(x_train, y_train, batch_size=32),\n\u001b[0m\u001b[1;32m     56\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#Original Epoch: 30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#VGG19 Netwok Using Augmentation\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load Data\n",
        "x_train = np.load('/content/Project/npy/x_train.npy')  # Assuming you have numpy arrays saved as 'train_data.npy'\n",
        "y_train = np.load('/content/Project/npy/y_train.npy')  # Assuming you have numpy arrays saved as 'train_labels.npy'\n",
        "x_test = np.load('/content/Project/npy/x_test.npy')  # Assuming you have numpy arrays saved as 'test_data.npy'\n",
        "y_test = np.load('/content/Project/npy/y_test.npy')  # Assuming you have numpy arrays saved as 'test_labels.npy'\n",
        "\n",
        "# Define your model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(248, 248, 3))\n",
        "\n",
        "# Fine-tune last few convolutional layers\n",
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG19\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(2)(x)  # Predict 2 coordinates\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Define callbacks for learning rate scheduling\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Train the model with data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
        "          epochs=30, #Original Epoch: 30\n",
        "          steps_per_epoch=len(x_train) / 32,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0lhmuL21nCu",
        "outputId": "779ee484-36e2-4e90-a357-8e25cffacbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 22s 22s/step\n",
            "Mean Squared Error: 14654.128110078605\n",
            "Mean Absolute Error: 107.9681409036412\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# Predict on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhmGO8m4cr25",
        "outputId": "92bd4944-159b-43c7-c152-d4b62f4584dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 290s 96s/step - loss: 1311727288320.0000 - val_loss: 135582.2656\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 278s 94s/step - loss: 57144.8789 - val_loss: 10411.3076\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 279s 94s/step - loss: 17316.3203 - val_loss: 10398.5957\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 279s 93s/step - loss: 17275.0137 - val_loss: 10290.1357\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 276s 94s/step - loss: 16983.6152 - val_loss: 9576.7734\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 274s 93s/step - loss: 15005.7686 - val_loss: 5045.8877\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 281s 97s/step - loss: 5269.4678 - val_loss: 19767.7129\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 273s 93s/step - loss: 5645.3975 - val_loss: 564.0797\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 273s 93s/step - loss: 4472.2354 - val_loss: 2343.1511\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 271s 92s/step - loss: 5661.2485 - val_loss: 1041.7804\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb577965510>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#VGG19 Netwok Using Keras Layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load your data\n",
        "x_train = np.load('/content/Project/npy/x_train.npy')\n",
        "y_train = np.load('/content/Project/npy/y_train.npy')\n",
        "x_test = np.load('/content/Project/npy/x_test.npy')\n",
        "y_test = np.load('/content/Project/npy/y_test.npy')\n",
        "\n",
        "# Preprocess your data (normalize, etc.)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define your model\n",
        "def create_custom_vgg19():\n",
        "    input_shape = (248, 248, 3)\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Construct the network\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(input_tensor)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool3')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool4')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_4')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool5')(x)\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc6')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc7')(x)\n",
        "    output = Dense(2, name='predictions')(x)  # Output layer with 2 neurons for coordinates\n",
        "    return Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "# Create the model\n",
        "model = create_custom_vgg19()\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AORI4YLXc671",
        "outputId": "a2204a83-21d5-40ed-819e-26bfa7943682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 13s 13s/step\n",
            "Mean Squared Error: 1041.7803505028771\n",
            "Mean Absolute Error: 29.72676681069767\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# Predict on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvbVLQgVoMEg",
        "outputId": "fe49ea77-8dd7-4b82-fc73-8590f59db826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294],\n",
              "       [ 25.82294, 102.25294]], dtype=float32)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xmXg7VjoQRk",
        "outputId": "89f2ed81-61a1-44e0-8f01-5f4c887d9f80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 62, 187],\n",
              "       [ 68, 113],\n",
              "       [ 46, 141],\n",
              "       [ 69, 115],\n",
              "       [ 56, 133],\n",
              "       [ 41, 138],\n",
              "       [ 51, 126],\n",
              "       [ 43, 136],\n",
              "       [ 50, 127],\n",
              "       [ 65, 118],\n",
              "       [ 50, 140],\n",
              "       [ 59, 122],\n",
              "       [ 56, 131],\n",
              "       [ 56, 128],\n",
              "       [ 56, 131],\n",
              "       [ 52, 133],\n",
              "       [ 63, 126]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "86NobIzk8juf"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"krishrajpal3@gmail.com\"\n",
        "!git config --global user.name \"krishrajpal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqflzAg89Bk_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
